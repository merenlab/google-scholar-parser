#!/usr/bin/enc/ python
#-*-coding: utf-8

###Imports
import argparse
from contextlib import redirect_stderr
import csv
import io
import os
import pathlib
from random import *
import re
from scholarly import scholarly #https://scholarly.readthedocs.io/en/latest/quickstart.html
                                #search-for-an-author-by-the-id-visible-in-the-url-of-an-authors-profile
                                #make adjustments with instructions found below:
                                    #https://github.com/scholarly-python-package/scholarly/issues/297
                                    #Adjustments made in July 16 and 20  versions
                                #July 16 and 20 version trigger error messages with fake_useragent
                                    #Make adjustments with instructions found below
                                        #https://github.com/hellysmile/fake-useragent/pull/110/commits/d8ca49d341829adb1f0efa7a309337bdc1c2b978
from scholarly import ProxyGenerator #Necessary for using ScraperAPI
import sys
import time
from time import sleep

__author__ = "Daniel Adam Nuccio"
__copyright__ = "X"
__liscense__ = "X"
__maintainer__ = "Daniel Adam Nuccio"
__email__ = "z1741403@students.niu.edu"
__requires__ = ["--user-ids", "--output-file"]
__provides__ = ["author-publication-information.tsv"]
__description__ =("A set of Python utilities to parse Google Scholar data")

def main(author_ids, output_file, random_interval_precaution, article_limit_precaution, verbosity):

    '''
    Implement Scholarly's ProxyGenerator to use ScraperAPI
    Unclear where to place it.
    Location immediately below only yields one call for one author and five pubs or two authors and one pub each.
    '''
    pg = ProxyGenerator()
    #pg.ScraperAPI('9a7b0111cac9972e465e0040b5f37bdf')
    #scholarly.use_proxy(pg)

    #Retrieve the author's data, fill-in, and return list of dictionaryies containing author and pub info
    dicList = []
    for a_id in author_ids:
        if verbosity == 1 or verbosity == 2: print('Processing: ', a_id)

        '''
        Here it appears to be called for each author.
        '''
        pg.ScraperAPI('9a7b0111cac9972e465e0040b5f37bdf')
        scholarly.use_proxy(pg)

        #Process valid IDs while flagging invalid IDs
        try:


            id = scholarly.search_author_id(a_id)
            name = id['name']
            if verbosity == 1 or verbosity == 2: print(name)

            author = scholarly.fill(id) #Fill author by ID
            numPub = len(author['publications'])
            if verbosity == 1 or verbosity == 2: print(name + ' has ' + str(numPub) + ' publications')

            random_intervals = genRandList(numPub) # See genRandList

            article_limit = determine_article_limit(article_limit_precaution, numPub)

            dicList = gather_pub_info(author, random_intervals, dicList, random_interval_precaution, article_limit, verbosity, pg)

        except AttributeError:
            print('An AttributeError occurred for ' + a_id)
            print('Please check to make sure this ID is correct.')

        except:
            print('Could not gather info for: ', a_id)

    #Produce final .tsv file
    produce_final_tsv(output_file, dicList)

class FilesNPathsError(Exception):
    pass

#Check input paths and process author IDs
def processInput(arg_dict):
    user_ids = arg_dict['user_ids']
    verbosity = arg_dict['verbosity']
    ###Check input file and path

    ####Is input a file?
    if len(user_ids) < 2:
        head, tail = os.path.split(user_ids[0])
        ext = pathlib.Path(tail).suffix
        ext = ext.lower()

        ####Does input path exist?
        if len(head) > 0:
            if not os.path.exists(user_ids[0]):
                try:
                    raise FilesNPathsError()
                except FilesNPathsError as e:
                    print('FilesNPathsError: Your input path does not exist. Please try again.')
                    sys.exit(1)

        ####Does file exist?
        if os.path.isfile(user_ids[0]):

            ####Is the file a .txt file?
            if not ext == '.txt':
                try:
                    raise FilesNPathsError()
                except FilesNPathsError as e:
                    print('Your file does not have the proper .txt extension')
                    sys.exit(1)

            ####Does user have permission to read?
            if not os.access(user_ids[0], os.R_OK):
                try:
                    raise FilesNPathsError()
                except FilesNPathsError as e:
                    print('FilesNPathsError: You do not have permission to read this file :(')
                    sys.exit(1)

            ####Is file empty?
            if os.stat(user_ids[0]).st_size==0:
                try:
                    raise FilesNPathsError()
                except FilesNPathsError as e:
                    print('FilesNPathsError: Your input file is empty :(')
                    sys.exit(1)

            ####Is file REALLY plain text?
            try:
                open(os.path.abspath(user_ids[0]), 'rU').read(512) #Do I need to close this?
            except UnicodeDecodeError:
                try:
                    raise FilesNPathsError()
                except FilesNPathsError as e:
                    print("FilesNPathsError: Your file does not seem to be plain a text file :/")
                    sys.exit(1)


            ####Process file if above conditions are met
            if verbosity == 1 or verbosity == 2: print('Processing ' + str(user_ids[0]))

            try:
                with open(user_ids[0], 'rU') as in_f:
                    preIdList = [id.strip() for id in in_f]
            except:
                print('Your file could not be processed :( Please make sure it is in fact a properly formatted text file.')
                sys.exit(1)

            author_ids = [id.replace(',', '') for id in preIdList]

            if verbosity == 1 or verbosity == 2:
                author_ids = list(filter(None, [id if len(id.split()) == 1 else print('The following ID was removed ' + str(id)) for id in author_ids]))
            else:
                author_ids = list(filter(None, [id  for id in author_ids if len(id.split()) == 1]))

            if verbosity == 1 or verbosity == 2: print('The following author ids will be processed:', author_ids)

        ####Process single ID if file does not exist
        else:
            if verbosity == 1 or verbosity == 2: print("Input does not appear to be a file. Therefore it will be processed as a single user ID.")
            if verbosity == 1 or verbosity == 2: print('Processing ID:')
            author_ids = [id.replace(',', '') for id in user_ids]
            if verbosity == 1 or verbosity == 2: print(author_ids[0])

    ###Process list of IDs
    else:
        if verbosity == 1 or verbosity == 2: print('You have entered a list of IDs.')
        if verbosity == 1 or verbosity == 2: print('The following ID(s) will be processed:')
        author_ids = [id.replace(',', '') for id in user_ids]
        if verbosity == 1 or verbosity == 2: print(*author_ids, sep='\n')
    return author_ids

def checkAuthorIDs(author_ids):

    return checked_author_ids


#Check output file and path
def checkOutputFile(arg_dict):
    output_file = arg_dict['output_file']
    head, tail = os.path.split(output_file)
    if len(head) > 0:

        ####Does path exist?
        if not os.path.exists(head):
            try:
                raise FilesNPathsError()
            except FilesNPathsError as e:
                print('FilesNPathsError: Your output path is invalid. Please try again.')
                sys.exit(1)

        ####Does user have permissions to write to directory?
        if not os.access(output_file, os.W_OK):
            try:
                raise FilesNPathsError()
            except FilesNPathsError as e:
                print('FilesNPathsError: You do not have permission to write to this directory :(')
                sys.exit(1)

    ####Does File Already Exist?
    if os.path.isfile(output_file):
        try:
            raise FilesNPathsError()
        except:
            print("FilesNPathsError: Let's try not to overwrite existing files")
            sys.exit(1)
    return output_file

def determine_article_limit(article_limit_precaution, number_of_publications):
    limit = 0

    if article_limit_precaution == None:
        limit = number_of_publications
    elif number_of_publications <= article_limit_precaution:
        limit = number_of_publications
    else:
        limit = article_limit_precaution

    return limit

#Generate random intervals for time between accessing publications
#as means to avoid upsetting Goliath
def genRandList(number_of_publications):
    randList = []
    n = 0
    while n < number_of_publications:
        n = n + 1
        ran = randint(30, 150)
        randList.append(ran)
    return randList

#Gather publication info
def gather_pub_info(author, random_intervals, dicList, random_interval_precaution, article_limit, verbosity, pg):

    i = 0
    for publication in author['publications']:
        if i < article_limit:

            try:
                pg.ScraperAPI('9a7b0111cac9972e465e0040b5f37bdf')
                scholarly.use_proxy(pg)

                nPub = scholarly.fill(author['publications'][i])
                if verbosity == 2: print(nPub)
                dicList.append(nPub)
            except:
                print('Could not get info for: ', publication) 

            t = random_intervals[i]

            i = i + 1
            if verbosity == 1 or verbosity == 2: print("Gathered data for pub " + str(i))

            if random_interval_precaution == 'True':
                if verbosity == 1 or verbosity == 2: print("Sleep for " + str(t) + " seconds")
                time.sleep(t)

    return dicList

#Write publication info to a .tsv file
def produce_final_tsv(output_file, dicList):
    with open(output_file, 'wt') as o_file:
        tsv_writer = csv.writer(o_file, delimiter='\t')
        tsv_writer.writerow(['Title', 'Authors', 'Year', 'Journal', 'Volume', 'Number', 'Pages'])
        for v in dicList:
            title = ''
            auth = ''
            year = ''
            jour = ''
            volu = ''
            numb = ''
            page = ''

            if 'title' in v['bib']:
                title = v['bib']['title']
                if verbosity == 2: print(title)
            else:
                title = 'NA'

            if 'author' in v['bib']:
                auth = format_authors(v['bib']['author'])
            else:
                auth = 'NA'

            if 'pub_year' in v['bib']:
                year = v['bib']['pub_year']
            else:
                year = 'NA'

            if 'journal' in v['bib']:
                jour = v['bib']['journal']
            else:
                jour = 'NA'

            if 'volume' in v['bib']:
                volu = v['bib']['volume']
            else:
                volu = 'NA'

            if 'number' in v['bib']:
                numb = v['bib']['number']
            else:
                numb = 'NA'

            if 'pages' in v['bib']:
                page = v['bib']['pages']
            else:
                page = 'NA'

            tsv_writer.writerow([title, auth, year, jour, volu, numb, page])

def format_authors(authors_in_scholarly_format):
    author_list = authors_in_scholarly_format.split(' and ')
    name_breakdown = []
    new_author_string = ''
    last_name = ''
    first_and_mi = []
    initials = []

    for name in author_list:
        name_breakdown = name.split(' ')
        last_name = name_breakdown[-1]
        first_and_mi = name_breakdown[:-1]
        #initials = [char[0] + '.' for char in first_and_mi]
        #new_author_string = new_author_string + last_name + ', ' + ' '.join(initials) + "; "
        new_author_string = new_author_string + last_name + ', ' + ' '.join(first_and_mi) + "; "


    return new_author_string

if __name__ == "__main__":
    ###Use Argparse to Take In Commandline Arguments
    parser = argparse.ArgumentParser(description = __description__, allow_abbrev= False) #provide description
                                                                                         #disable abbreviated args

    requiredNamed = parser.add_argument_group('Required Arguments')
    requiredNamed.add_argument('--user-ids', nargs = "+",
                                required=True,
                                help = "One or more IDs entered via the commandline or in a single .txt file with the appropriate '.txt' extension")
    requiredNamed.add_argument("--output-file",
                                required = True,
                                help = "Output file with publication info in .tsv format")

    precautionsNamed = parser.add_argument_group('Precautions to Avoid Angering Google')
    precautionsNamed.add_argument("--random-interval-precaution", choices = ['True', 'False'], default = 'True',
                                    help = "Scrapes article data at random intervals of 30-150s to appear more human and decrease the liklihood of making Google angry.(This feature will be turned on by default. Disable at your own risk...)")
    precautionsNamed.add_argument("--article-limit-precaution", choices = [None, 1, 5], type = int, default = None,
                                    help = "Limit the number of articles scraped from Google to 1 or 5 for testing purposes.")

    miscellaneousNamed = parser.add_argument_group('Arguments to customize your experience with this program.')
    miscellaneousNamed.add_argument('--verbosity', choices = [0, 1, 2], type = int, default = 1,
                                        help = 'Customize how much information you want concerning the progress of your search. (Default equals 1. Error messages will always be printed because there is always room for self-improvement ;)')

    ###Print full help message if proper arguments not given

    known_args, unknown_args = parser.parse_known_args()

    '''
    if known_args.user_ids is None or known_args.output_file is None:
        parser.error('--user-ids and --output-file are required arguments. Please make sure these fields are entered.')
        sys.exit(1)
    '''

    if unknown_args != []:
        print("It appears you have entered an invalid argument :/")
        #parser.print_help()
        sys.exit(1)

    #args = parser.parse_args()

    #if args.verbosity == 1: print('You entered the following arguments:', args)
    arg_dict = known_args.__dict__

    if arg_dict['verbosity'] == 1:
        print('\nYou entered the following arguments:')
        for k, v in arg_dict.items(): print(k, ': ', v)
        print('\n')

    user_ids = processInput(arg_dict)
    output_file = checkOutputFile(arg_dict)
    random_interval_precaution = arg_dict['random_interval_precaution']
    article_limit_precaution = arg_dict['article_limit_precaution']
    verbosity = arg_dict['verbosity']
    main(user_ids, output_file, random_interval_precaution, article_limit_precaution, verbosity)
